{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btech/mayank.kumar/miniconda3/envs/TransPolymer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '/home/btech/mayank.kumar/Hritik/Multi-Task')\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, RobertaModel\n",
    "from PolymerSmilesTokenization import PolymerSmilesTokenizer\n",
    "from multiTask_dataset import MultiTask_Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../ckpt/pretrain.pt were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../ckpt/pretrain.pt and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'PolymerSmilesTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = pd.read_csv('../data/multiTask.csv')\n",
    "data = data.sample(frac=1.0, random_state=42)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "train_data , test_data = train_test_split(data ,random_state=42, test_size=0.20, shuffle=False)\n",
    "\n",
    "PretrainedModel = RobertaModel.from_pretrained('../ckpt/pretrain.pt')\n",
    "tokenizer = PolymerSmilesTokenizer.from_pretrained(\"roberta-base\", max_len=411)\n",
    "PretrainedModel.config.hidden_dropout_prob = 0.1\n",
    "PretrainedModel.config.attention_probs_dropout_prob = 0.1\n",
    "max_token_len = 411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Eea</th>\n",
       "      <th>Egb</th>\n",
       "      <th>Egc</th>\n",
       "      <th>Ei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*NC(=S)NC(=S)*</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>2.8537</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*Oc1ccc(Oc2ccc(OC(*)=O)cc2)cc1</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>4.7541</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*NCC(F)(F)C(*)(F)F</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>7.8675</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>8.2676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*CCCCCCCCCCOC(=O)CC(C)(C)CC(=O)O*</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>6.7584</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*CCCCCCNC(=O)C(CCCCCCCCCCCCCCC)C(=O)N*</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>*CC(CO*)(CS(=O)(=O)CCCC)CS(=O)(=O)CCCC</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>5.4465</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>*CCCCCCCCCCNC(=O)CCP(C)(=O)CCC(=O)N*</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>5.8056</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>*Oc1c(-c2ccccc2)cc(*)cc1-c1cccc(C)c1</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>3.8976</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>*CCC(=O)OC(=O)CCC1CCC(*)O1</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>5.5098</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>*c1ccc(Cc2ccc(N3C(=O)c4ccc([Si](C)(C)c5ccc6c(c...</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>2.9801</td>\n",
       "      <td>-99.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2972 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles      Eea      Egb  \\\n",
       "0                                        *NC(=S)NC(=S)* -99.0000 -99.0000   \n",
       "1                        *Oc1ccc(Oc2ccc(OC(*)=O)cc2)cc1 -99.0000 -99.0000   \n",
       "2                                    *NCC(F)(F)C(*)(F)F   0.6587   7.8675   \n",
       "3                     *CCCCCCCCCCOC(=O)CC(C)(C)CC(=O)O* -99.0000 -99.0000   \n",
       "4                *CCCCCCNC(=O)C(CCCCCCCCCCCCCCC)C(=O)N* -99.0000 -99.0000   \n",
       "...                                                 ...      ...      ...   \n",
       "2967             *CC(CO*)(CS(=O)(=O)CCCC)CS(=O)(=O)CCCC -99.0000 -99.0000   \n",
       "2968               *CCCCCCCCCCNC(=O)CCP(C)(=O)CCC(=O)N* -99.0000 -99.0000   \n",
       "2969               *Oc1c(-c2ccccc2)cc(*)cc1-c1cccc(C)c1 -99.0000 -99.0000   \n",
       "2970                         *CCC(=O)OC(=O)CCC1CCC(*)O1 -99.0000 -99.0000   \n",
       "2971  *c1ccc(Cc2ccc(N3C(=O)c4ccc([Si](C)(C)c5ccc6c(c... -99.0000 -99.0000   \n",
       "\n",
       "          Egc       Ei  \n",
       "0      2.8537 -99.0000  \n",
       "1      4.7541 -99.0000  \n",
       "2    -99.0000   8.2676  \n",
       "3      6.7584 -99.0000  \n",
       "4      5.9375 -99.0000  \n",
       "...       ...      ...  \n",
       "2967   5.4465 -99.0000  \n",
       "2968   5.8056 -99.0000  \n",
       "2969   3.8976 -99.0000  \n",
       "2970   5.5098 -99.0000  \n",
       "2971   2.9801 -99.0000  \n",
       "\n",
       "[2972 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Eea</th>\n",
       "      <th>Egb</th>\n",
       "      <th>Egc</th>\n",
       "      <th>Ei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>*Nc1ccc(C(C)(C)c2ccc(NC(=O)c3cc(C(*)=O)cc(N4C(...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>3.5748</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>*c1cccc(C(F)(F)C(F)(F)C(*)(F)F)c1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>5.5439</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>*CCN(*)C(=O)c1ccc(F)cc1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>5.1588</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>*c1ccc2cc(N(*)c3ccccc3)ccc2c1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2.8541</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>*Nc1cc(C)c(*)cc1C</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>3.9275</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>*CCCCCOC(=O)C(=O)O*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>5.5658</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>*CCCCCCCCCCCCNC(=O)CCCCC(=O)N*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>5.5516</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>*c1ccc(Oc2ccc(-c3cnc4ccc(-c5ccc6ncc(*)nc6c5)cc...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>3.2298</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>*CCOCCOC(=O)NC(=CC=C1(C))C=C1NC(=O)O*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>5.0931</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>*CC(O)CN(*)c1ccc(N=Nc2ccc(C(=O)O)cc2)cc1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2.4267</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles   Eea   Egb     Egc  \\\n",
       "2972  *Nc1ccc(C(C)(C)c2ccc(NC(=O)c3cc(C(*)=O)cc(N4C(... -99.0 -99.0  3.5748   \n",
       "2973                  *c1cccc(C(F)(F)C(F)(F)C(*)(F)F)c1 -99.0 -99.0  5.5439   \n",
       "2974                            *CCN(*)C(=O)c1ccc(F)cc1 -99.0 -99.0  5.1588   \n",
       "2975                      *c1ccc2cc(N(*)c3ccccc3)ccc2c1 -99.0 -99.0  2.8541   \n",
       "2976                                  *Nc1cc(C)c(*)cc1C -99.0 -99.0  3.9275   \n",
       "...                                                 ...   ...   ...     ...   \n",
       "3711                                *CCCCCOC(=O)C(=O)O* -99.0 -99.0  5.5658   \n",
       "3712                     *CCCCCCCCCCCCNC(=O)CCCCC(=O)N* -99.0 -99.0  5.5516   \n",
       "3713  *c1ccc(Oc2ccc(-c3cnc4ccc(-c5ccc6ncc(*)nc6c5)cc... -99.0 -99.0  3.2298   \n",
       "3714              *CCOCCOC(=O)NC(=CC=C1(C))C=C1NC(=O)O* -99.0 -99.0  5.0931   \n",
       "3715           *CC(O)CN(*)c1ccc(N=Nc2ccc(C(=O)O)cc2)cc1 -99.0 -99.0  2.4267   \n",
       "\n",
       "        Ei  \n",
       "2972 -99.0  \n",
       "2973 -99.0  \n",
       "2974 -99.0  \n",
       "2975 -99.0  \n",
       "2976 -99.0  \n",
       "...    ...  \n",
       "3711 -99.0  \n",
       "3712 -99.0  \n",
       "3713 -99.0  \n",
       "3714 -99.0  \n",
       "3715 -99.0  \n",
       "\n",
       "[744 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MultiTask_Dataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_token_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataset = dataset\n",
    "        self.max_token_len = max_token_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        self.len = len(self.dataset)\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        data_row = self.dataset.iloc[i]\n",
    "\n",
    "        smile = data_row[0]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            str(smile),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        props = []\n",
    "        loss_mask = []\n",
    "\n",
    "        for i in range(1,5):\n",
    "            props.append(data_row[i])\n",
    "            if(data_row[i]==-99):\n",
    "                loss_mask.append(0)\n",
    "            else:\n",
    "                loss_mask.append(1)\n",
    "\n",
    "        props = torch.tensor(props)\n",
    "        loss_mask = torch.tensor(loss_mask)\n",
    "\n",
    "        return dict(\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            smile = smile,\n",
    "            smile_len = len(smile)+2,\n",
    "            props=props,\n",
    "            loss_mask = loss_mask\n",
    "        )\n",
    "    \n",
    "class MultiTask_DataAugmentation:\n",
    "    def __init__(self, aug_indicator):\n",
    "        super(MultiTask_DataAugmentation, self).__init__()\n",
    "        self.aug_indicator = aug_indicator\n",
    "\n",
    "    \"\"\"Rotate atoms to generate more SMILES\"\"\"\n",
    "    def rotate_atoms(self, li, x):\n",
    "        return (li[x % len(li):] + li[:x % len(li)])\n",
    "\n",
    "    \"\"\"Generate SMILES\"\"\"\n",
    "    def generate_smiles(self, smiles, prop):\n",
    "        smiles_list = []\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "        except:\n",
    "            mol = None\n",
    "        if mol != None:\n",
    "            n_atoms = mol.GetNumAtoms()\n",
    "            n_atoms_list = [nat for nat in range(n_atoms)]\n",
    "            if n_atoms != 0:\n",
    "                for iatoms in range(n_atoms):\n",
    "                    n_atoms_list_tmp = self.rotate_atoms(n_atoms_list, iatoms)  # rotate atoms' index\n",
    "                    nmol = Chem.RenumberAtoms(mol, n_atoms_list_tmp)  # renumber atoms in mol\n",
    "                    try:\n",
    "                        smiles = Chem.MolToSmiles(nmol,\n",
    "                                                  isomericSmiles=True,  # keep isomerism\n",
    "                                                  kekuleSmiles=False,  # kekulize or not\n",
    "                                                  rootedAtAtom=-1,  # default\n",
    "                                                  canonical=False,  # canonicalize or not\n",
    "                                                  allBondsExplicit=False,  #\n",
    "                                                  allHsExplicit=False)  #\n",
    "                    except:\n",
    "                        smiles = 'None'\n",
    "                    smiles_list.append(smiles)\n",
    "            else:\n",
    "                smiles = 'None'\n",
    "                smiles_list.append(smiles)\n",
    "        else:\n",
    "            try:\n",
    "                smiles = Chem.MolToSmiles(mol,\n",
    "                                          isomericSmiles=True,  # keep isomerism\n",
    "                                          kekuleSmiles=False,  # kekulize or not\n",
    "                                          rootedAtAtom=-1,  # default\n",
    "                                          canonical=False,  # canonicalize or not\n",
    "                                          allBondsExplicit=False,  #\n",
    "                                          allHsExplicit=False)  #\n",
    "            except:\n",
    "                smiles = 'None'\n",
    "            smiles_list.append(smiles)\n",
    "        smiles_array = pd.DataFrame(smiles_list).drop_duplicates().values\n",
    "        # \"\"\"\n",
    "        if int(prop[0])==-99 and int(prop[1])==-99 and int(prop[3])==-99:\n",
    "            smiles_aug = smiles_array[1:, :]\n",
    "            np.random.shuffle(smiles_aug)\n",
    "            smiles_array = np.vstack((smiles_array[0, :], smiles_aug[:self.aug_indicator-1, :]))\n",
    "        return smiles_array\n",
    "\n",
    "    \"\"\"SMILES Augmentation\"\"\"\n",
    "    def smiles_augmentation(self, df):\n",
    "        column_list = df.columns\n",
    "        data_aug = np.zeros((1, df.shape[1]))\n",
    "        for i in range(df.shape[0]):\n",
    "            smiles = df.iloc[i, 0]\n",
    "            prop = df.iloc[i, 1:]\n",
    "            smiles_array = self.generate_smiles(smiles,prop)\n",
    "            if 'None' not in smiles_array:\n",
    "                prop = np.tile(prop, (len(smiles_array), 1))\n",
    "                data_new = np.hstack((smiles_array, prop))\n",
    "                data_aug = np.vstack((data_aug, data_new))\n",
    "        df_aug = pd.DataFrame(data_aug[1:, :], columns=column_list)\n",
    "        return df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, outputs, props, loss_mask, properties):\n",
    "        loss = {}\n",
    "        for i,property in enumerate(properties):\n",
    "            loss[property] = torch.sum(((outputs[:,i]-props[:,i])*loss_mask[:,i])**2.0)  / (1 if torch.sum(loss_mask[:,i])==0 else \n",
    "                                                                                            torch.sum(loss_mask[:,i]))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MT Model\"\"\"\n",
    "class MultiTask(nn.Module):\n",
    "    def __init__(self, drop_rate=0.1):\n",
    "        super(MultiTask, self).__init__()\n",
    "        \n",
    "        self.PretrainedModel = deepcopy(PretrainedModel)\n",
    "        self.PretrainedModel.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        self.Eea_FCNN = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "        self.Egb_FCNN = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "        self.Egc_FCNN = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "        self.Ei_FCNN = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, smile_len, batch_size):\n",
    "        fingerprint = torch.empty(batch_size,768)\n",
    "        outputs = self.PretrainedModel(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        for i in range(batch_size):   \n",
    "            fingerprint[i] = torch.mean(outputs.last_hidden_state[i, 0:smile_len[i], :],dim=0)\n",
    "            \n",
    "        fingerprint = (fingerprint.to(device)).double()\n",
    "\n",
    "        Eea_FCNN_output = self.Eea_FCNN(fingerprint)\n",
    "        Egb_FCNN_output = self.Egb_FCNN(fingerprint)\n",
    "        Egc_FCNN_output = self.Egc_FCNN(fingerprint)\n",
    "        Ei_FCNN_output = self.Ei_FCNN(fingerprint)\n",
    "        \n",
    "        final_output = torch.cat([Eea_FCNN_output,Egb_FCNN_output,Egc_FCNN_output,Ei_FCNN_output], dim=1)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2score(y_pred, y_actual, mask):\n",
    "    bool_mask = mask.bool()\n",
    "    masked_y_pred = y_pred[bool_mask]\n",
    "    masked_y_actual = y_actual[bool_mask]\n",
    "\n",
    "    ssr = torch.sum((masked_y_pred - masked_y_actual)**2)\n",
    "    sst = torch.sum((masked_y_actual - torch.mean(masked_y_actual))**2)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, Loss, train_dataloader, device, properties):\n",
    "    print(\"Inside Train function \")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        smile_len = batch[\"smile_len\"].to(device)\n",
    "        batch_size = len(smile_len)\n",
    "        loss_mask = batch[\"loss_mask\"].to(device)\n",
    "        props = batch[\"props\"].to(device)\n",
    "        outputs = model(input_ids, attention_mask, smile_len, batch_size).float()\n",
    "        total_loss = 0.0\n",
    "        loss = Loss(outputs, props.float(), loss_mask, properties)\n",
    "        for i,property in enumerate(properties):\n",
    "            total_loss += loss[property]\n",
    "        print(total_loss)\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, Loss, train_dataloader, test_dataloader, device, scaler, optimizer, epoch, properties):\n",
    "\n",
    "    train_loss = {}\n",
    "    test_loss = {}\n",
    "    r2_train = {}\n",
    "    r2_test = {}\n",
    "\n",
    "    for i,property in enumerate(properties):\n",
    "        train_loss[property] = 0.0\n",
    "        test_loss[property] = 0.0\n",
    "        r2_train[property] = 0.0\n",
    "        r2_test[property] = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_pred = {property: [] for property in properties}\n",
    "        train_true = {property: [] for property in properties}\n",
    "        test_pred = {property: [] for property in properties}\n",
    "        test_true = {property: [] for property in properties}\n",
    "        train_loss_mask = {property: [] for property in properties}\n",
    "        test_loss_mask = {property: [] for property in properties}\n",
    "        \n",
    "        print(\"Inside Train_Dataloader\")\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            smile_len = batch[\"smile_len\"].to(device)\n",
    "            loss_mask = batch[\"loss_mask\"].to(device)            \n",
    "            props = batch[\"props\"].to(device)\n",
    "            batch_size = len(smile_len)\n",
    "            outputs = model(input_ids, attention_mask, smile_len, batch_size).float()\n",
    "\n",
    "            for i,property in enumerate(properties):\n",
    "                outputs[:,i] = torch.from_numpy(scaler[i].inverse_transform(outputs[:,i].cpu()))\n",
    "                props[:,i] = torch.from_numpy(scaler[i].inverse_transform(props[:,i].cpu()))\n",
    "            \n",
    "            loss = Loss(outputs, props.float(), loss_mask, properties)\n",
    "\n",
    "            for i,property in enumerate(properties):\n",
    "                train_loss[property] += loss[property].item() * torch.sum(loss_mask[:,i])\n",
    "                train_pred[property].append(outputs[:, i].unsqueeze(1).double().to(device))\n",
    "                train_true[property].append(props[:, i].unsqueeze(1).double().to(device)) \n",
    "                train_loss_mask[property].append(loss_mask[:, i].unsqueeze(1).double().to(device))\n",
    "            print(\"End of Batch -----------------------------------------------------------------\")\n",
    "\n",
    "        for i,property in enumerate(properties):\n",
    "            train_pred[property] = torch.cat(train_pred[property], dim=0)\n",
    "            train_true[property] = torch.cat(train_true[property], dim=0)\n",
    "            train_loss_mask[property] = torch.cat(train_loss_mask[property], dim=0)\n",
    "\n",
    "        for i,property in enumerate(properties):    \n",
    "            train_loss[property] = train_loss[property] / torch.sum(train_loss_mask[property])\n",
    "            print(f'train loss for {property} after epoch is {train_loss[property]} and mask is {torch.sum(train_loss_mask[property])}')\n",
    "            r2_train[property] = r2score(train_pred[property].flatten().to(\"cpu\"), train_true[property].flatten().to(\"cpu\"), train_loss_mask[property].flatten().to(\"cpu\"))\n",
    "            print(f'train {property} RMSE = ', torch.sqrt(train_loss[property]).item())\n",
    "            print(f'train {property} r^2 = ', r2_train[property].item())\n",
    "        \n",
    "        print(\"Inside Test_Dataloader\")\n",
    "        for step, batch in enumerate(test_dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            smile_len = batch[\"smile_len\"].to(device)\n",
    "            loss_mask = batch[\"loss_mask\"].to(device)            \n",
    "            props = batch[\"props\"].to(device)\n",
    "            batch_size = len(smile_len)\n",
    "            outputs = model(input_ids, attention_mask, smile_len, batch_size).float()\n",
    "\n",
    "            for i,property in enumerate(properties):\n",
    "                outputs[:,i] = torch.from_numpy(scaler[i].inverse_transform(outputs[:,i].cpu()))\n",
    "                props[:,i] = torch.from_numpy(scaler[i].inverse_transform(props[:,i].cpu()))\n",
    "            \n",
    "            loss = Loss(outputs, props.float(), loss_mask, properties)\n",
    "            \n",
    "            for i,property in enumerate(properties):\n",
    "                test_loss[property] += loss[property].item() * torch.sum(loss_mask[:,i])\n",
    "                test_pred[property].append(outputs[:, i].unsqueeze(1).double().to(device))\n",
    "                test_true[property].append(props[:, i].unsqueeze(1).double().to(device)) \n",
    "                test_loss_mask[property].append(loss_mask[:, i].unsqueeze(1).double().to(device))\n",
    "            print('End of Batch ---------------------------------------------- -------------------------')\n",
    "\n",
    "        for i,property in enumerate(properties):\n",
    "            test_pred[property] = torch.cat(test_pred[property], dim=0)\n",
    "            test_true[property] = torch.cat(test_true[property], dim=0)\n",
    "            test_loss_mask[property] = torch.cat(test_loss_mask[property], dim=0)\n",
    "\n",
    "        for i,property in enumerate(properties):    \n",
    "            test_loss[property] = test_loss[property] / torch.sum(test_loss_mask[property])\n",
    "            print(f'test loss for {property} after epoch is {test_loss[property]} and mask is {torch.sum(test_loss_mask[property])}')\n",
    "            r2_test[property] = r2score(test_pred[property].flatten().to(\"cpu\"), test_true[property].flatten().to(\"cpu\"), test_loss_mask[property].flatten().to(\"cpu\"))\n",
    "            print(f'test {property} RMSE = ', torch.sqrt(test_loss[property]).item())\n",
    "            print(f'test {property} r^2 = ', r2_test[property].item())\n",
    "\n",
    "    return train_loss, test_loss, r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Eea</th>\n",
       "      <th>Egb</th>\n",
       "      <th>Egc</th>\n",
       "      <th>Ei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>*Nc1ccc(C(C)(C)c2ccc(NC(=O)c3cc(C(*)=O)cc(N4C(...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.606232</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>*c1cccc(C(F)(F)C(F)(F)C(*)(F)F)c1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.654547</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>*CCN(*)C(=O)c1ccc(F)cc1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.407975</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>*c1ccc2cc(N(*)c3ccccc3)ccc2c1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-1.067683</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>*Nc1cc(C)c(*)cc1C</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.380404</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>*CCCCCOC(=O)C(=O)O*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.668569</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>*CCCCCCCCCCCCNC(=O)CCCCC(=O)N*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.659477</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>*c1ccc(Oc2ccc(-c3cnc4ccc(-c5ccc6ncc(*)nc6c5)cc...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.827129</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>*CCOCCOC(=O)NC(=CC=C1(C))C=C1NC(=O)O*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.365908</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>*CC(O)CN(*)c1ccc(N=Nc2ccc(C(=O)O)cc2)cc1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-1.341339</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles   Eea   Egb       Egc  \\\n",
       "2972  *Nc1ccc(C(C)(C)c2ccc(NC(=O)c3cc(C(*)=O)cc(N4C(... -99.0 -99.0 -0.606232   \n",
       "2973                  *c1cccc(C(F)(F)C(F)(F)C(*)(F)F)c1 -99.0 -99.0  0.654547   \n",
       "2974                            *CCN(*)C(=O)c1ccc(F)cc1 -99.0 -99.0  0.407975   \n",
       "2975                      *c1ccc2cc(N(*)c3ccccc3)ccc2c1 -99.0 -99.0 -1.067683   \n",
       "2976                                  *Nc1cc(C)c(*)cc1C -99.0 -99.0 -0.380404   \n",
       "...                                                 ...   ...   ...       ...   \n",
       "3711                                *CCCCCOC(=O)C(=O)O* -99.0 -99.0  0.668569   \n",
       "3712                     *CCCCCCCCCCCCNC(=O)CCCCC(=O)N* -99.0 -99.0  0.659477   \n",
       "3713  *c1ccc(Oc2ccc(-c3cnc4ccc(-c5ccc6ncc(*)nc6c5)cc... -99.0 -99.0 -0.827129   \n",
       "3714              *CCOCCOC(=O)NC(=CC=C1(C))C=C1NC(=O)O* -99.0 -99.0  0.365908   \n",
       "3715           *CC(O)CN(*)c1ccc(N=Nc2ccc(C(=O)O)cc2)cc1 -99.0 -99.0 -1.341339   \n",
       "\n",
       "        Ei  \n",
       "2972 -99.0  \n",
       "2973 -99.0  \n",
       "2974 -99.0  \n",
       "2975 -99.0  \n",
       "2976 -99.0  \n",
       "...    ...  \n",
       "3711 -99.0  \n",
       "3712 -99.0  \n",
       "3713 -99.0  \n",
       "3714 -99.0  \n",
       "3715 -99.0  \n",
       "\n",
       "[744 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = ['Eea','Egb','Egc','Ei']\n",
    "scaler = []\n",
    "            \n",
    "for i,property in enumerate(properties):\n",
    "    scaled = StandardScaler()\n",
    "\n",
    "    train_data.loc[train_data[property] != -99, property] = scaled.fit_transform(\n",
    "        train_data.loc[train_data[property] != -99, [property]]).flatten()\n",
    "\n",
    "    test_data.loc[test_data[property] != -99, property] = scaled.transform(\n",
    "        test_data.loc[test_data[property] != -99, [property]]).flatten()\n",
    "                \n",
    "    scaler.append(scaled)\n",
    "    \n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augamentation\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Augamentation\")\n",
    "DataAug = MultiTask_DataAugmentation(2)\n",
    "train_data = DataAug.smiles_augmentation(train_data)\n",
    "\n",
    "\"\"\"Train the model\"\"\"\n",
    "model = MultiTask(drop_rate=0.1).to(device)\n",
    "model = model.double()\n",
    "Loss = MaskedLoss()\n",
    "\n",
    "optimizer = AdamW(\n",
    "            [\n",
    "                {\"params\": model.PretrainedModel.parameters(), \"lr\": 0.00005,\n",
    "                         \"weight_decay\": 0.0},\n",
    "                {'params': model.Eea_FCNN.parameters(), 'lr': 0.0001, 'weight_decay': 0.01},\n",
    "                {'params': model.Egb_FCNN.parameters(), 'lr': 0.0001, 'weight_decay': 0.01},\n",
    "                {'params': model.Egc_FCNN.parameters(), 'lr': 0.0001, 'weight_decay': 0.01},\n",
    "                {'params': model.Ei_FCNN.parameters(), 'lr': 0.0001, 'weight_decay': 0.01}                     \n",
    "            ],\n",
    "            no_deprecation_warning=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiTask_Dataset(train_data,tokenizer, 411)\n",
    "test_dataset = MultiTask_Dataset(test_data,tokenizer, 411)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Eea</th>\n",
       "      <th>Egb</th>\n",
       "      <th>Egc</th>\n",
       "      <th>Ei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*NC(=S)NC(=S)*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-1.067939</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*C(NC(N*)=S)=S</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-1.067939</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Oc1ccc(Oc2ccc(OC(*)=O)cc2)cc1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.148853</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=C(Oc1ccc(Oc2ccc(O*)cc2)cc1)*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.148853</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*NCC(F)(F)C(*)(F)F</td>\n",
       "      <td>-1.5757</td>\n",
       "      <td>1.895784</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2.061071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>*c1cc(-c2cccc(C)c2)c(O*)c(-c2ccccc2)c1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.399549</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12178</th>\n",
       "      <td>*CCC(=O)OC(=O)CCC1CCC(*)O1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.632714</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>O1C(CCC(OC(CC*)=O)=O)CCC1*</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.632714</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12180</th>\n",
       "      <td>*c1ccc(Cc2ccc(N3C(=O)c4ccc([Si](C)(C)c5ccc6c(c...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.987007</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12181</th>\n",
       "      <td>c1c([Si](C)(C)c2ccc3c(c2)C(=O)N(*)C3=O)cc2c(c1...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.987007</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12182 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  smiles     Eea       Egb  \\\n",
       "0                                         *NC(=S)NC(=S)*   -99.0     -99.0   \n",
       "1                                         *C(NC(N*)=S)=S   -99.0     -99.0   \n",
       "2                         *Oc1ccc(Oc2ccc(OC(*)=O)cc2)cc1   -99.0     -99.0   \n",
       "3                         O=C(Oc1ccc(Oc2ccc(O*)cc2)cc1)*   -99.0     -99.0   \n",
       "4                                     *NCC(F)(F)C(*)(F)F -1.5757  1.895784   \n",
       "...                                                  ...     ...       ...   \n",
       "12177             *c1cc(-c2cccc(C)c2)c(O*)c(-c2ccccc2)c1   -99.0     -99.0   \n",
       "12178                         *CCC(=O)OC(=O)CCC1CCC(*)O1   -99.0     -99.0   \n",
       "12179                         O1C(CCC(OC(CC*)=O)=O)CCC1*   -99.0     -99.0   \n",
       "12180  *c1ccc(Cc2ccc(N3C(=O)c4ccc([Si](C)(C)c5ccc6c(c...   -99.0     -99.0   \n",
       "12181  c1c([Si](C)(C)c2ccc3c(c2)C(=O)N(*)C3=O)cc2c(c1...   -99.0     -99.0   \n",
       "\n",
       "            Egc        Ei  \n",
       "0     -1.067939     -99.0  \n",
       "1     -1.067939     -99.0  \n",
       "2      0.148853     -99.0  \n",
       "3      0.148853     -99.0  \n",
       "4         -99.0  2.061071  \n",
       "...         ...       ...  \n",
       "12177 -0.399549     -99.0  \n",
       "12178  0.632714     -99.0  \n",
       "12179  0.632714     -99.0  \n",
       "12180 -0.987007     -99.0  \n",
       "12181 -0.987007     -99.0  \n",
       "\n",
       "[12182 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Train function \n",
      "tensor(11.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.0453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.5048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.7981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.4923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.6567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.7457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7106, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.8868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.4237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.2530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.4457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.3642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4562, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.1101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.6933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.4283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.1327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.8834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.1601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.7309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.9898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.2473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.5683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7425, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.7464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.4804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Starting of Test Function\n",
      "Inside Train_Dataloader\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "End of Batch -----------------------------------------------------------------\n",
      "train loss for Eea after epoch is 1.0461963659843052 and mask is 4253.0\n",
      "train Eea RMSE =  1.0228374093590364\n",
      "train Eea r^2 =  -0.014078029545335102\n",
      "train loss for Egb after epoch is 3.509830681190125 and mask is 6785.0\n",
      "train Egb RMSE =  1.8734542111271695\n",
      "train Egb r^2 =  -0.009235249938387424\n",
      "train loss for Egc after epoch is 2.767751730685086 and mask is 7999.0\n",
      "train Egc RMSE =  1.6636561335459579\n",
      "train Egc r^2 =  -0.03327560796568951\n",
      "train loss for Ei after epoch is 0.9124375799524854 and mask is 4275.0\n",
      "train Ei RMSE =  0.9552159860222637\n",
      "train Ei r^2 =  0.005051948861921174\n",
      "Inside Test_Dataloader\n",
      "End of Batch ---------------------------------------------- -------------------------\n",
      "End of Batch ---------------------------------------------- -------------------------\n",
      "End of Batch ---------------------------------------------- -------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train(model, optimizer, Loss, train_dataloader, device, properties)\n",
    "    print(\"Starting of Test Function\")\n",
    "    test(model, Loss, train_dataloader, test_dataloader, device, scaler, optimizer, epoch, properties)\n",
    "    print('End of Epoch//////////////////////////////////////////////////////////////////////////////////')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TransPolymer",
   "language": "python",
   "name": "transpolymer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
